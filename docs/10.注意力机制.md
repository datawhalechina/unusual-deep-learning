æ³¨æ„åŠ›æœºåˆ¶

è®°å¿†ç½‘ç»œ



# æ³¨æ„åŠ›æœºåˆ¶

### äººç±»çš„æ³¨æ„åŠ›æœºåˆ¶

<img src="./PIC/Attention/3.png" alt="3" style="zoom:50%;" />

åœ¨æ·±åº¦å­¦ä¹ ä¸­æ³¨æ„åŠ›æœºåˆ¶çš„ç ”ç©¶ï¼š

<img src="./PIC/Attention/1.png" alt="1" style="zoom:50%;" />

å‚è€ƒï¼š
[1] Recurrent Models of Visual Attention. NIPS 2014: 2204- 2212
[2] Neural machine translation by jointly learning to align and translate, ICLR 2015
[3] Show, Attend and Tell: Neural Image Caption Generation with Visual Attentionï¼ŒICML 2015
[4] Attention is all you needï¼ŒNIPS 2017

### æ³¨æ„åŠ›æœºåˆ¶åœ¨åœ¨ç¥ç»æœºå™¨ç¿»è¯‘é¢†åŸŸçš„åº”ç”¨

- ç¥ç»æœºå™¨ç¿»è¯‘ä¸»è¦ä»¥Encoder-Decoderæ¨¡å‹ä¸ºåŸºç¡€ç»“æ„

<img src="./PIC/Attention/4.png" alt="4" style="zoom:50%;" />

- åœ¨ç¥ç»æœºå™¨ç¿»è¯‘ä¸­ï¼ŒEncoderä¸€èˆ¬é‡‡ç”¨RNNæˆ–è€…LSTMå®ç°
  - ä»ç»Ÿè®¡è§’åº¦ï¼Œç¿»è¯‘ç›¸å½“äºå¯»æ‰¾è¯‘å¥yï¼Œä½¿å¾—ç»™å®šåŸå¥ x æ—¶æ¡ä»¶æ¦‚ç‡æœ€å¤§ï¼š$\arg \max _{y} p(\boldsymbol{y} \mid \boldsymbol{x})$
  - å¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡ c çš„æ–¹æ³•æœ‰å¾ˆå¤šï¼Œå¯ä»¥ç›´æ¥å°†æœ€åä¸€ä¸ªéšçŠ¶æ€ä½œä¸ºä¸Šä¸‹æ–‡å˜é‡ï¼Œä¹Ÿå¯å¯¹æœ€åçš„éšçŠ¶æ€è¿›è¡Œä¸€ä¸ªéçº¿æ€§å˜æ¢ $\sigma(\cdot)$ï¼Œæˆ–å¯¹æ‰€æœ‰çš„éšçŠ¶æ€è¿›è¡Œéçº¿æ€§å˜æ¢ $\sigma()$

$$
c =h_{T} \\  \,\,\,\  c =\sigma\left(h_{T}\right) \\ c =\sigma\left(h_{1}, h_{2}, \cdots, h_{T}\right)
$$

### è§£ç å™¨

- ç”¨ç»™å®šçš„ä¸Šä¸‹æ–‡å‘é‡cå’Œä¹‹å‰å·²ç»é¢„æµ‹çš„è¯ $\{y_1,\cdots,y_{t-1}\}$

<img src="./PIC/Attention/5.png" alt="5" style="zoom:50%;" />

### ç°å­˜é—®é¢˜

-  è¾“å…¥åºåˆ—ä¸è®ºé•¿çŸ­éƒ½ä¼šè¢«ç¼–ç æˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤ºï¼Œè€Œè§£ç åˆ™å—é™äºè¯¥å›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤º
- è¿™ä¸ªé—®é¢˜é™åˆ¶äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯å½“è¾“å…¥åºåˆ—æ¯”è¾ƒé•¿æ—¶ï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šå˜å¾—å¾ˆå·®

### ç¥ç»ç½‘ç»œæ¨¡å‹æ³¨æ„åŠ›æœºåˆ¶

<img src="./PIC/Attention/8.png" alt="6" style="zoom:33%;" />

- åœ¨è¿™ä¸ªæ–°ç»“æ„ä¸­ï¼Œå®šä¹‰æ¯ä¸ªè¾“å‡ºçš„æ¡ä»¶æ¦‚ç‡ä¸º:  $p\left(y_{i} \mid y_{1}, \cdots, y_{i-1}, \boldsymbol{x}\right)=g\left(y_{i-1}, x_{i}, c_{i}\right)$.
- å…¶ä¸­ $ğ‘ _ğ‘–$ ä¸ºè§£ç å™¨RNNä¸­çš„éšå±‚çŠ¶æ€: $s_{i}=f\left(s_{i-1}, y_{i-1}, c_{i}\right)$.
- è¿™é‡Œçš„ä¸Šä¸‹æ–‡å‘é‡ $ğ‘_ğ‘–$ å–å†³äºæ³¨é‡Šå‘é‡åºåˆ— (encoderè½¬åŒ–å¾—åˆ°)ï¼Œé€šè¿‡ä½¿ç”¨æ³¨æ„åŠ›ç³»æ•° $ğ›¼_{ğ‘–ğ‘—}$ å¯¹ $h_ğ‘—$  åŠ æƒæ±‚å¾—ï¼š

$$
c_{i}=\sum_{j=1}^{T} \alpha_{i j} h_{j}
$$

<img src="./PIC/Attention/9.png" alt="9" style="zoom:50%;" />

### æ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—

æ³¨æ„åŠ›ç³»æ•°è®¡ç®—ï¼š
$$
\alpha_{i j}=\frac{\exp \left(e_{i j}\right)}{\sum_{k=1}^{T_{x}} \exp \left(e_{i k}\right)} \quad e_{i j}=a\left(s_{i-1}, h_{j}\right)
$$
åä¸€ä¸ªå…¬å¼ä¸­çš„ $a(\cdot)$ è¡¨ç¤ºalignment modeï¼Œåæ˜  $i$ ä½ç½®çš„è¾“å…¥å’Œ $j$ ä½ç½®è¾“å‡ºçš„åŒ¹é…ç¨‹åº¦ã€‚

è®¡ç®—æ³¨æ„åŠ›ç³»æ•°çš„ç›¸ä¼¼å‡½æ•°(alignment model)æœ‰ä»¥ä¸‹å‡ ç§ï¼š
$$
a\left(s_{i-1}, h_{j}\right) = 
h_{j}^{T} \cdot s_{i-1} \\
a\left(s_{i-1}, h_{j}\right) = 
\frac{h_{j}^{T} \cdot W_{\alpha} \cdot s_{i-1}}{W_{\alpha} \cdot\left[h_{j}^{T}, s_{i-1}^{T}\right]^{T}} \\
a\left(s_{i-1}, h_{j}\right) = 
v_{\alpha} \tanh \left(U_{\alpha} h_{j}+W_{\alpha} s_{i-1}\right)
$$

### å‡ ç§ä¸»æµçš„æ³¨æ„åŠ›æœºåˆ¶

<img src="./PIC/Attention/6.png" alt="6" style="zoom:50%;" />

### æ³¨æ„åŠ›æœºåˆ¶çš„ç†è§£

- Attentionå‡½æ•°çš„æœ¬è´¨å¯ä»¥è¢«æè¿°ä¸ºä¸€ä¸ªæŸ¥è¯¢(query)åˆ°ä¸€ ç³»åˆ—(é”®key-å€¼value)å¯¹çš„æ˜ å°„

<img src="./PIC/Attention/7.png" alt="7" style="zoom:50%;" />
$$
\text { Attention(Query, Source })=\sum_{i=1}^{L_{x}} \text { similarity }\left(\text { Query }, \mathrm{Key}_{i}\right){\times} \text { Value }_{i}
$$

å‚è€ƒæ–‡çŒ®ï¼šVaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]. Advances in Neural Information Processing Systems. 2017: 6000-6010.

æ³¨æ„åŠ›ç³»æ•°è®¡ç®—

- é˜¶æ®µ1ï¼šæ ¹æ®Queryå’ŒKeyè®¡ç®—ä¸¤è€…çš„ç›¸ä¼¼æ€§æˆ–è€…ç›¸å…³æ€§
- é˜¶æ®µ2ï¼šå¯¹ç¬¬ä¸€é˜¶æ®µçš„åŸå§‹åˆ†å€¼è¿› è¡Œå½’ä¸€åŒ–å¤„ç†
- é˜¶æ®µ3ï¼šæ ¹æ®æƒé‡ç³»æ•°å¯¹Valueè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°Attention Value

<img src="./PIC/Attention/12.png" alt="7" style="zoom:50%;" />

Self-attention layer in â€œAttention is all you needâ€

<img src="./PIC/Attention/13.png" alt="7" style="zoom:50%;" />

<img src="./PIC/Attention/14.png" alt="7" style="zoom:50%;" />

<img src="./PIC/Attention/15.png" alt="7" style="zoom:50%;" />

<img src="./PIC/Attention/16.png" alt="7" style="zoom:50%;" />

### æ³¨æ„åŠ›æœºåˆ¶çš„åº”ç”¨

- GPT/GPT-2
- BERT

<img src="./PIC/Attention/17.png" alt="7" style="zoom:50%;" />


# è®°å¿†ç½‘ç»œ

### äº§ç”ŸèƒŒæ™¯

ç°ä»£è®¡ç®—æœºçš„ä¸€ä¸ªå·¨å¤§ä¼˜åŠ¿å°±æ˜¯å¯ä»¥å¯¹ä¿¡æ¯è¿›è¡Œå­˜å‚¨ã€‚ä½† æ˜¯ï¼Œå¤§å¤šæ•°æœºå™¨å­¦ä¹ æ¨¡å‹ç¼ºå°‘è¿™ç§å¯ä»¥è¯»å–ã€å†™å…¥çš„é•¿æœŸ è®°å¿†çš„å†…å­˜ç»“æ„ã€‚RNNã€LSTMè¿™æ ·çš„ç¥ç»ç½‘ç»œåŸåˆ™ä¸Šå¯ä»¥å®ç°è®°å¿†å­˜å‚¨ï¼Œ ä½†æ˜¯ï¼Œå®ƒä»¬ç”±éšè—çŠ¶æ€å’Œæƒé‡ç¼–ç åŒ…å«çš„è®°å¿†å¤ªå°äº†ï¼Œä¸èƒ½è®°å¿†è¶³å¤Ÿä¿¡æ¯ã€‚åŸºäºæ­¤ï¼ŒFacebook AI Researchæå‡ºäº†ä¸€ç§ç”¨äºé—®ç­”ä»»åŠ¡çš„è®°å¿†ç½‘ç»œï¼Œå®ç°äº†è®°å¿†çš„å­˜å‚¨ã€‚å¹¿ä¹‰ä¸Šè®²ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œä¹Ÿæ˜¯è®°å¿†ç½‘ç»œçš„ä¸€ç§

### ä»£è¡¨å·¥ä½œ

- **Memory Networks**. ICLR 2015

- **End-To-End Memory Networks**. NIPS 2015: 2440-2448

- **Key-Value Memory Networks for Directly Reading Documents**. EMNLP 2016: 1400-1409

- **Tracking the World State with Recurrent Entity Networks**. ICLR 2017

### ç»“æ„

ç»“æ„ç¤ºæ„å›¾ï¼š I, G, O, Rå››ä¸ªæ¨¡å—

<img src="./PIC/Attention/2.png" alt="2" style="zoom:50%;" />

å‚è€ƒï¼šWeston, Jason, Sumit Chopra, and Antoine Bordes. "Memory networks." arXiv preprint arXiv:1410.3916 (2014).

- Input vectorï¼šå°†è¾“å…¥x(å­—ç¬¦ã€å•è¯ã€å¥å­ç­‰ä¸åŒçš„ç²’åº¦)è½¬æˆå†…éƒ¨ç‰¹å¾å‘é‡çš„è¡¨ç¤º $ I(x)$
- Generalizationï¼šæ ¹æ®æ–°çš„è¾“å…¥æ›´æ–°è®°å¿†å•å…ƒä¸­çš„memory slot $m_i$ï¼Œ$\boldsymbol{m}_{\boldsymbol{i}}=G\left(\boldsymbol{m}_{\boldsymbol{i}}, \boldsymbol{I}(\boldsymbol{x}), \boldsymbol{m}\right), \forall i$.

- Output feature mapï¼šæ ¹æ®è®°å¿†å•å…ƒå’Œæ–°çš„è¾“å…¥ï¼Œè¾“å‡ºç‰¹å¾ $o = O(x, m)$

- Responseï¼šæœ€åï¼Œè§£ç è¾“å‡ºç‰¹å¾ $o$ï¼Œå¹¶ç»™å‡ºå¯¹åº”çš„å“åº” $r = R(o)$ï¼ŒRå¯ä»¥æ˜¯ä¸€ä¸ªRNNç½‘ç»œç”Ÿæˆå›ç­”çš„å¥å­ï¼Œæ›´ç®€å•çš„è¯å¯ä»¥è®¡ç®—ç›¸å…³åˆ†æ•°ï¼Œæ¯”å¦‚Wæ˜¯ä¸€ä¸ªå•è¯é›†åˆ(dictionary)

### ç«¯åˆ°ç«¯çš„è®°å¿†ç½‘ç»œ

**å•å±‚å’Œä¸‰å±‚ç½‘ç»œ**

å‚è€ƒï¼šSukhbaatar, Sainbayar, Arthur Szlam, Jason Weston, and Rob Fergus. "End-to-end memory networks." arXiv preprint arXiv:1503.08895(2015).

<img src="./PIC/Attention/10.png" alt="10" style="zoom:50%;" />

**è®­ç»ƒå‚æ•°**

- A:inputembeddingmatrix
- C: output embedding matrix
- W: answer prediction matrix
- B: question embedding matrix

**æŸå¤±å‡½æ•°**ï¼šäº¤å‰ç†µ

### **Key-Value**è®°å¿†ç½‘ç»œ

é¢å‘**QA**çš„**Key-Value**ç½‘ç»œç»“æ„

- é«˜æ•ˆçš„çŸ¥è¯†å­˜å‚¨å’Œæ£€ç´¢
  - keyè´Ÿè´£å¯»å€lookupï¼Œä¹Ÿå°±æ˜¯å¯¹memoryä¸Questionçš„ç›¸å…³ç¨‹åº¦è¿›è¡Œè¯„åˆ†ï¼Œ
  - valueåˆ™è´Ÿè´£readingï¼Œä¹Ÿå°±æ˜¯å¯¹è®°å¿†çš„å€¼è¿›è¡ŒåŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡º

<img src="./PIC/Attention/11.png" alt="11" style="zoom:50%;" />

### å…¶å®ƒè®°å¿†ç½‘ç»œ

- **2017**å¹´ï¼Œ**Facebook AI Research**æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºè®°å¿†ç½‘ ç»œçš„å¾ªç¯å®ä½“ç½‘ç»œï¼Œå…¶ä½¿ç”¨å›ºå®šé•¿åº¦çš„è®°å¿†å•å…ƒæ¥å­˜å‚¨ä¸– ç•Œä¸Šçš„å®ä½“ï¼Œä¸»è¦å­˜å‚¨è¯¥å®ä½“ç›¸å…³çš„å±æ€§ï¼Œä¸”è¯¥è®°å¿†ä¼šéš ç€è¾“å…¥å†…å®¹å®æ—¶æ›´æ–°

- **Google DeepMind**ä¹Ÿæå‡ºäº†å¤šç§è®°å¿†ç½‘ç»œï¼Œå¦‚:**Neural Turing Machines**ã€**Neural Random Access Machines**ä»¥åŠä½¿ ç”¨åƒæ ˆæˆ–(åŒç«¯)é˜Ÿåˆ—ç»“æ„çš„è¿ç»­ç‰ˆæœ¬ç­‰

- åˆ©ç”¨å¤–éƒ¨å­˜å‚¨å½¢å¼çš„æœºå™¨å­¦ä¹ æ–¹å¼å·²ç»æˆä¸ºæœºå™¨å­¦ä¹ é¢†åŸŸä¸­ä¸€ä¸ªçƒ­ç‚¹æ–¹å‘
